{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "d2rmvoiqpx24u3c6tjos",
   "authorId": "5744486210470",
   "authorName": "CCARRERO",
   "authorEmail": "carlos.carrero@snowflake.com",
   "sessionId": "158f8502-a574-40b4-8121-da6cbfdbea3f",
   "lastEditTime": 1744072850482
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "DEV, TEST and PROD deployments will be hold in different SCHEMAS"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "# Then, we can use the python name to turn cell2 into a Pandas dataframe\nsession.sql('create or replace schema DATASET').collect()\nsession.sql('use schema DATASET').collect()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "643651c3-d14e-41b5-a806-4982d29b52ee",
   "metadata": {
    "language": "sql",
    "name": "cell32"
   },
   "outputs": [],
   "source": "use schema DATASET",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7998a3b0-6e33-4aba-a5ba-18a9e6e42718",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "Here we are using the power of Cortex LLMs to create some feedback comments"
  },
  {
   "cell_type": "code",
   "id": "482550db-5314-4247-9587-a3a6ec50b010",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport random\nfrom datetime import datetime, timedelta\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark import functions as F\nfrom snowflake import snowpark\n\ndef uc01_feature_engineering_generation(db, sc, sales_tb, feedback_tb, cur_date, table_name):\n\n    # Function to create features that define a profile of customer behavior based on latest purchases\n    # Features created for a given date (cur_date)\n    # New features added into table (table_name)\n\n    table_name = f'{db}.{sc}.{table_name}'\n    \n    # Load data\n    customers_tbl = '.'.join([db, sc,'CUSTOMERS'])\n    sales_tbl = '.'.join([db, sc, sales_tb])\n    feedback_tbl = '.'.join([db, sc, feedback_tb])\n    \n    customers_df = session.table(customers_tbl)\n    sales_df = session.table(sales_tbl)\n    sales_df_last_tran = session.table(sales_tbl)\n\n    feedback_sentiment_df = session.table(feedback_tbl)    \n\n    # we are only doing feature engineering for transactions before cur_date\n    \n    sales_df_last_tran = sales_df_last_tran.filter(F.col(\"transaction_date\") < F.lit(cur_date))\n\n    sales_df = sales_df.filter(F.col(\"transaction_date\") < F.lit(cur_date ))\n        \n    # count only feedback before cur_date\n    \n    feedback_sentiment_df = feedback_sentiment_df.filter(F.col(\"chat_date\") < F.lit(cur_date))\n    \n    sales_agg_df = (\n        sales_df_last_tran.group_by(\"customer_id\")\n        .agg(\n            F.max(\"transaction_date\").alias(\"last_purchase_date\"),\n            F.sum(\"total_amount\").alias(\"total_customer_value\")\n        )\n    )\n    \n    def custom_column_naming(input_col, agg, window):\n        return f\"{agg}_{input_col}_{window.replace('-', 'past_')}\"\n                                                   \n    sales_agg_orders_df = sales_df.analytics.time_series_agg(\n            time_col=\"transaction_date\",\n            aggs={\"total_amount\": [\"SUM\", \"COUNT\"]},\n            windows=[\"-7D\",\"-1MM\", \"-2MM\", \"-3MM\"],\n            sliding_interval=\"1D\",\n            group_by=[\"CUSTOMER_ID\"],\n            col_formatter = custom_column_naming)\n\n    sales_agg_last_purchase = sales_agg_df.join(\n        sales_agg_orders_df,\n        (sales_agg_df.last_purchase_date == sales_agg_orders_df.transaction_date) &\n        (sales_agg_df.CUSTOMER_ID == sales_agg_orders_df.CUSTOMER_ID),\n        \"left\").select(\n            sales_agg_df[\"customer_id\"].alias(\"CUSTOMER_ID\"),\n            sales_agg_df[\"total_customer_value\"],\n            sales_agg_df[\"last_purchase_date\"],\n            sales_agg_orders_df[\"SUM_TOTAL_AMOUNT_PAST_7D\"],\n            sales_agg_orders_df[\"SUM_TOTAL_AMOUNT_PAST_1MM\"],\n            sales_agg_orders_df[\"SUM_TOTAL_AMOUNT_PAST_2MM\"],\n            sales_agg_orders_df[\"SUM_TOTAL_AMOUNT_PAST_3MM\"],\n            sales_agg_orders_df[\"COUNT_TOTAL_AMOUNT_PAST_7D\"],\n            sales_agg_orders_df[\"COUNT_TOTAL_AMOUNT_PAST_1MM\"],\n            sales_agg_orders_df[\"COUNT_TOTAL_AMOUNT_PAST_2MM\"],\n            sales_agg_orders_df[\"COUNT_TOTAL_AMOUNT_PAST_3MM\"]\n        )\n\n    #  feedback data\n\n    latest_feedback_df = (feedback_sentiment_df.group_by(\"customer_id\")\n            .agg(F.max(\"chat_date\").alias(\"chat_date\")))\n    \n    feedback_agg_df = feedback_sentiment_df.analytics.moving_agg(\n            aggs={\"SENTIMENT\": [\"MIN\", \"AVG\"]},\n            window_sizes=[2, 3, 4],\n            order_by=[\"chat_date\"],\n            group_by=[\"CUSTOMER_ID\"])\n\n    \n    feedback_agg_latest_df = latest_feedback_df.join(\n        feedback_agg_df, \"customer_id\", \"left\").select(\n            latest_feedback_df[\"CUSTOMER_ID\"].alias(\"CUSTOMER_ID\"),\n            feedback_agg_df[\"SENTIMENT_MIN_2\"],\n            feedback_agg_df[\"SENTIMENT_MIN_3\"],\n            feedback_agg_df[\"SENTIMENT_MIN_4\"],\n            feedback_agg_df[\"SENTIMENT_AVG_2\"],\n            feedback_agg_df[\"SENTIMENT_AVG_3\"],\n            feedback_agg_df[\"SENTIMENT_AVG_4\"],         \n        )\n\n    feedback_agg_latest_df.show(10)\n    \n    # Join tables\n    features_df = (\n        customers_df.join(sales_agg_last_purchase, \"customer_id\", \"left\")\n        .join(feedback_agg_latest_df, \"customer_id\", \"left\")\n        .select(\n            customers_df[\"customer_id\"],\n            customers_df[\"age\"],\n            customers_df[\"gender\"],\n            customers_df[\"location\"],\n            customers_df[\"customer_segment\"],\n            sales_agg_last_purchase[\"last_purchase_date\"],\n            feedback_agg_latest_df[\"SENTIMENT_MIN_2\"],\n            feedback_agg_latest_df[\"SENTIMENT_MIN_3\"],\n            feedback_agg_latest_df[\"SENTIMENT_MIN_4\"],\n            feedback_agg_latest_df[\"SENTIMENT_AVG_2\"],\n            feedback_agg_latest_df[\"SENTIMENT_AVG_3\"],\n            feedback_agg_latest_df[\"SENTIMENT_AVG_4\"],\n            sales_agg_last_purchase[\"SUM_TOTAL_AMOUNT_PAST_7D\"],\n            sales_agg_last_purchase[\"SUM_TOTAL_AMOUNT_PAST_1MM\"],\n            sales_agg_last_purchase[\"SUM_TOTAL_AMOUNT_PAST_2MM\"],\n            sales_agg_last_purchase[\"SUM_TOTAL_AMOUNT_PAST_3MM\"],\n            sales_agg_last_purchase[\"COUNT_TOTAL_AMOUNT_PAST_7D\"].alias(\"COUNT_ORDERS_PAST_7D\"),\n            sales_agg_last_purchase[\"COUNT_TOTAL_AMOUNT_PAST_1MM\"].alias(\"COUNT_ORDERS_PAST_1MM\"),\n            sales_agg_last_purchase[\"COUNT_TOTAL_AMOUNT_PAST_2MM\"].alias(\"COUNT_ORDERS_PAST_2MM\"),\n            sales_agg_last_purchase[\"COUNT_TOTAL_AMOUNT_PAST_3MM\"].alias(\"COUNT_ORDERS_PAST_3MM\"),\n            F.datediff(\"day\", sales_agg_df[\"last_purchase_date\"], F.lit(cur_date)).alias(\"DAYS_SINCE_LAST_PURCHASE\"),\n            F.lit(cur_date).alias(\"TIMESTAMP\")\n        ).filter(sales_agg_df[\"last_purchase_date\"].isNotNull()  # Avoid customers never purchased\n        ).dropDuplicates([\"customer_id\", \"TIMESTAMP\"])  # Ensure one combination of customer_id and TIMESTAMP\n\n    )\n    \n    # Fill with 0 those where we have no data (so neutral feedback and zero iterations and amount)\n    columns_to_fill = [\n        \"SENTIMENT_MIN_2\", \"SENTIMENT_MIN_3\", \"SENTIMENT_MIN_4\", \"SENTIMENT_AVG_2\",\n        \"SENTIMENT_AVG_3\", \"SENTIMENT_AVG_4\",\n        \"SUM_TOTAL_AMOUNT_PAST_7D\", \"SUM_TOTAL_AMOUNT_PAST_1MM\", \"SUM_TOTAL_AMOUNT_PAST_2MM\", \"SUM_TOTAL_AMOUNT_PAST_3MM\",\n        \"COUNT_ORDERS_PAST_7D\", \"COUNT_ORDERS_PAST_1MM\", \"COUNT_ORDERS_PAST_2MM\", \"COUNT_ORDERS_PAST_3MM\"\n    ]\n    \n    for column in columns_to_fill:\n        features_df = features_df.fillna({column: 0})\n    \n    # Write to Snowflake Table\n    features_df.write.mode(\"append\").save_as_table(table_name)\n\n    print (f'Created table {table_name}')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90121591-b3b2-4e0e-91d9-0d05bb17c298",
   "metadata": {
    "language": "python",
    "name": "Create_feedback_comments"
   },
   "outputs": [],
   "source": "comments_sql= \"\"\"\n        create or replace table comments_temp (id number, comment VARCHAR) as \n        \n        select 1, snowflake.cortex.complete ('mistral-large2', 'write comment complaining about the product SkiBoots123. They were broken after 2 days of usage. You are very dissatified')\n        UNION\n        select 2, snowflake.cortex.complete ('mistral-large2', 'write comment complaining about a defect in a recent purchase indicating you are not satisfied and will not buy in the shop again. Do not indicate any date, product or shop ')\n        UNION\n        select 3, snowflake.cortex.complete ('mistral-large2', 'write comment complaining about a recent shipment where the package was broken. Do not indicate any date, product or shop ')\n        UNION\n        select 4, snowflake.cortex.complete ('mistral-large2', 'write comment where you complain a litte bit about support not calling you back. Do not indicate any date, product or shop ')\n        UNION\n        select 5, snowflake.cortex.complete ('mistral-large2', 'write a neutral coment about a recent call you had with support. Do not indicate any date, product or shop ')\n        UNION\n        select 6, snowflake.cortex.complete ('mistral-large2', 'write a neutral comment about a recent purchase you have done. Do not indicate any date, product or shop ')\n        UNION\n        select 7, snowflake.cortex.complete ('mistral-large2', 'write a comment indicating you are satisfied with a recent purchase. Do not indicate any date, product or shop ')\n        UNION\n        select 8, snowflake.cortex.complete ('mistral-large2', 'write a comment indicating you are satisfied with a recent purchase and you will recommend the shop. Do not indicate any date, product or shop ')\n        UNION\n        select 9, snowflake.cortex.complete ('mistral-large2', 'write a comment indicating you are satisfied with a recent support received by a shop assistant. Do not indicate any date, product or shop ')\n\n        \"\"\"\n\ncomments_tb = session.sql(comments_sql).collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "125b718f-ac5d-4a6e-87cf-fab858582ab2",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": "select * from comments_temp;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5adc9c2e-aa17-4bf2-9b84-d4bb89ec1559",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "drop table if exists customers;\ndrop table if exists sales;\ndrop table if exists feedback_raw;\ndrop table if exists feedback_sentiment;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "68f04740-6f13-49c4-8356-2ddcf5c2dcea",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "Function to add some fake data. This will generate customers, transactions and feedback that will be used later to understand customer purchase behaviours and detect when a customer is on high probability of not buying again so we can take some actions"
  },
  {
   "cell_type": "code",
   "id": "41456c5e-f126-41c3-b477-2ed64761cab7",
   "metadata": {
    "language": "python",
    "name": "generate_data_function"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport random\nfrom datetime import datetime, timedelta\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark import functions as F\n\nnum_customers = 5000\nnum_transactions = num_customers * 15\nnum_feedback_reports = num_customers * 2\n\npayment_methods = ['Credit Card', 'Paypal', 'Apple Pay']\nproduct_segments = ['Fashion', 'Electronics', 'Beauty', 'Groceries', 'Home', 'Toys', 'Books']\nlocations = ['Madrid', 'Barcelona', 'Paris', 'London', 'Munich', 'Rome', 'NY', 'Lisbon', 'SFO', 'Denver', 'Atlanta', 'Chicago', 'LAS']\ncustomer_segments = ['Planitum', 'Gold', 'Silver', 'Standard']\n\n\ndef generate_data (first_transaction_date, period):\n\n    customers = []\n    for i in range(num_customers):\n        customer_id = f\"CUST-{i}\"\n        age = random.randint(18, 99)\n        gender = 'Male' if random.choice([True, False]) else 'Female'\n        location = random.choice(locations)\n        signup_date = first_transaction_date - timedelta(days=random.randint(365,900))\n        customer_segment = random.choice(customer_segments)\n        \n        customers.append ([customer_id, age, gender, location, signup_date, customer_segment])\n\n    df_customers = pd.DataFrame(customers, columns= [\n        \"CUSTOMER_ID\", \"AGE\", \"GENDER\", \"LOCATION\", \"SIGNUP_DATE\", \"CUSTOMER_SEGMENT\"\n    ])\n\n    customers = session.create_dataframe(df_customers).drop_duplicates()\n    customers = customers.with_column(\"signup_date\", F.col(\"signup_date\").cast(T.DateType()))\n    customers.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS\")\n\n    transactions = []\n    for i in range(num_transactions):\n        transaction_id = f\"TRANS-{i+1}\"\n        customer_id = f\"CUST-{random.randint(1, num_customers)}\"\n        transaction_date = first_transaction_date + timedelta(days=random.randint(0,period))\n        total_amount = round(random.uniform(50, 5000), 2)\n        num_items = random.randint(1, 10)\n        discount_applied = bool(random.randint(0, 1))\n        payment_method = random.choice(payment_methods)\n        \n        transactions.append([transaction_id, customer_id, transaction_date, total_amount, num_items, discount_applied, payment_method])\n\n    # Creating the DataFrame for transactions\n    df_transactions = pd.DataFrame(transactions, columns=[\n        \"TRANSACTION_ID\", \"CUSTOMER_ID\", \"TRANSACTION_DATE\", \"TOTAL_AMOUNT\", \n        \"NUM_ITEMS\", \"DISCOUNT_APPLIED\", \"PAYMENT_METHOD\"\n    ])\n\n    transactions = session.create_dataframe(df_transactions).drop_duplicates()\n    transactions = transactions.with_column(\"transaction_date\", F.col(\"transaction_date\").cast(T.DateType()))\n    transactions.write.mode(\"overwrite\").save_as_table(\"SALES\")\n    \n   # Feedback data generation\n\n    comments_df = session.table(\"comments_temp\")\n    \n    feedback_df = session.sql(f\"\"\"\n        SELECT \n        'FB-' || TO_CHAR(SEQ8()) AS feedback_id,\n        'CUST-' || TO_CHAR(UNIFORM(1, 5000, RANDOM())) AS customer_id,\n        DATEADD(DAY, -UNIFORM(0, 365, RANDOM()), CURRENT_DATE) AS chat_date,\n        UNIFORM(1, 9, RANDOM()) AS internal_id\n    FROM TABLE(GENERATOR(ROWCOUNT => {num_feedback_reports}))\n    \"\"\")\n    \n    final_feedback_df = feedback_df.join(comments_df, feedback_df[\"internal_id\"] == comments_df[\"id\"]) \\\n                                    .select(feedback_df[\"feedback_id\"], \n                                            feedback_df[\"customer_id\"], \n                                            feedback_df[\"chat_date\"], \n                                            feedback_df[\"internal_id\"], \n                                            comments_df[\"comment\"])\n    \n    final_feedback_df.write.mode(\"overwrite\").save_as_table(\"FEEDBACK_RAW\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9a7243a8-1c51-4908-be9c-80754636bd7b",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "To simulate the data feeds, we are going to generate 3 months of data from 18 months since now that will be used as a baseline to them simulate more sales for customers"
  },
  {
   "cell_type": "code",
   "id": "f0e134c0-e39c-44c2-80eb-86cf752dee60",
   "metadata": {
    "language": "python",
    "name": "generate_base_data",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import calendar\n\nnum_days_per_batch = 31\n\nnow = datetime.now()\nlast_day = calendar.monthrange(now.year, now.month)[1]\nlast_day_of_month = datetime(now.year, now.month, last_day).date()\n\n#Go back 1 year ago + 3 months\nfirst_timestamp = last_day_of_month - timedelta(days=14* num_days_per_batch)\n\n# Generate data for 3 months\ngenerate_data(first_timestamp, num_days_per_batch * 3)  ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d740a90-d041-4e19-860a-b7742d5670bc",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": "select min(transaction_date), max(transaction_date) from sales;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ace2bf07-1b2a-4aa1-b5c4-42bb3cc34234",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "Here we can use the power of LLMs to understand customer feedback and provide a sentiment score that we will be using later to determine probability of churn\n"
  },
  {
   "cell_type": "code",
   "id": "698e4493-abf7-4626-b44a-14b4a79c22da",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "from snowflake.cortex import sentiment\nimport snowflake.snowpark.functions as F\n\n\nfeedback_raw_df = session.table(\"feedback_raw\")\n\nfeedback_sentiment_df = feedback_raw_df.with_columns([\"sentiment\"], [sentiment(F.col(\"comment\"))])\n\nfeedback_sentiment_df.write.mode(\"overwrite\").save_as_table(\"feedback_sentiment\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ad82286-e1a5-4343-9dfb-b1f4bfc5121a",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "### Feature Engineering\n\nThis function will create a profile for each customer who has already made a purchase in the shop. For a given timestamp, it will analyze the past transactions and feedback and using Snowflake analytical functions will generate features that will be used to traind and predict models.\n"
  },
  {
   "cell_type": "code",
   "id": "3848256a-33fd-4d13-9364-ffa370d49616",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": "sales_df = session.table(\"sales\")\n\nfirst_sale_timestamp = sales_df.select(F.min(F.col(\"transaction_date\"))).collect()[0][0]\n\nlast_sale_timestamp = sales_df.select(F.max(F.col(\"transaction_date\"))).collect()[0][0]\n\nprint (f'First sale:{first_sale_timestamp}')\nprint (f'Last sale: {last_sale_timestamp}')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0588b582-481f-4a3c-b638-0b2c9828deb8",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1358bbd2-c5f6-4bfa-9de5-edd55e2f684e",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "### Generate monthly purchase based on customer behaviors"
  },
  {
   "cell_type": "code",
   "id": "220ad6ff-21e2-4908-8156-b9d5ddf8bd6f",
   "metadata": {
    "language": "python",
    "name": "add_more_sales_with_churn"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport random\nfrom datetime import datetime, timedelta\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark import functions as F\nfrom snowflake import snowpark\n\ndef add_new_top_sales (session: snowpark.Session, churn_base_table: str, \n                       new_sales_table:str , days_window: int):\n\n    def add_transactions (df, last_sales_timestamp, days_window):\n    \n        transactions = []\n        \n        for customer in df:\n\n            for i in range(random.randint(1,5)): #between 1 and 10 transactions in the period\n                customer_id = customer[\"CUSTOMER_ID\"]\n                    \n                payment_methods = ['Credit Card', 'Paypal', 'Apple Pay']\n            \n                transaction_id = f\"TRANS-N\"\n                customer_id = customer_id\n                \n                #if round(random.randint(1,10)) >= 6: # 60% buy in the entire period\n                days=random.randint(1,days_window)\n                #else: # the rest buy in the first quarter\n                #    days=random.randint(1,round(days_window/4)+1)\n\n                transaction_date = last_sales_timestamp + timedelta(days=random.randint(1,days))\n                \n                total_amount = round(random.uniform(50, 5000), 2)\n                num_items = random.randint(1, 5)\n                discount_applied = bool(random.randint(0, 1))\n                payment_method = random.choice(payment_methods)\n                    \n                transactions.append([transaction_id, customer_id, transaction_date, total_amount, num_items, discount_applied, payment_method])\n        \n        # Creating the DataFrame for transactions\n        df_transactions = pd.DataFrame(transactions, columns=[\n            \"TRANSACTION_ID\", \"CUSTOMER_ID\", \"TRANSACTION_DATE\", \"TOTAL_AMOUNT\", \n            \"NUM_ITEMS\", \"DISCOUNT_APPLIED\", \"PAYMENT_METHOD\"\n        ])\n        \n        df_transactions[\"TRANSACTION_DATE\"] = pd.to_datetime(df_transactions[\"TRANSACTION_DATE\"], errors=\"coerce\")\n    \n        transactions = session.create_dataframe(df_transactions).drop_duplicates()\n        transactions = transactions.with_column(\"TRANSACTION_DATE\", F.to_date(F.col(\"TRANSACTION_DATE\")))\n\n       # transactions = transactions.with_column(\"transaction_date\", F.col(\"transaction_date\").cast(T.DateType()))\n        transactions.write.mode(\"append\").save_as_table(new_sales_table)\n     \n        num_tran = transactions.count()\n        print (f'added {num_tran} transactions')\n\n    churn_df = session.table(churn_base_table)\n        \n    latest_timestamp = churn_df.select(F.max(F.col(\"TIMESTAMP\"))).collect()[0][0]\n    \n    churn_df = churn_df.filter(F.col(\"TIMESTAMP\") == F.lit(latest_timestamp))\n\n    num_customers = churn_df.select(\"CUSTOMER_ID\").distinct().count()\n\n    \n    all_customers_ordered_sentiment = churn_df.select(\"CUSTOMER_ID\").orderBy(F.col(\"SENTIMENT_AVG_2\").desc()).collect()\n\n    churn_rate = random.uniform(0.45, 0.55)\n    num_churn = int(num_customers * churn_rate)\n\n    churn_customers = all_customers_ordered_sentiment[:num_churn]\n    active_customers = all_customers_ordered_sentiment[num_churn:]\n    \n    last_sales_timestamp = session.table(\"sales\").select(F.max(F.col(\"transaction_date\"))).collect()[0][0]\n    \n\n    print (\"Add for active customers\")\n    add_transactions(active_customers, last_sales_timestamp, days_window)\n\n\n    def add_sentiment(df, happy):\n        #add sentiment but no transactions for chun customers\n        feedback = []\n    \n        for customer in df:\n            feedback_id = 'FEEDBACK-N'\n            customer_id = customer[\"CUSTOMER_ID\"]\n            customer_id = customer_id\n            chat_date = last_sales_timestamp + timedelta(days=random.randint(1,days_window))\n            if happy:\n                internal_id = random.randint(6, 9) #from angry to neutral\n            else:\n                internal_id = random.randint(1, 4) #from angry to neutral\n            \n            feedback.append([feedback_id, customer_id, chat_date, internal_id])\n    \n        df_feedback = pd.DataFrame(feedback, columns=[\n                \"FEEDBACK_ID\", \"CUSTOMER_ID\", \"CHAT_DATE\",\n                \"INTERNAL_ID\"\n        ])\n    \n        feedback = session.create_dataframe(df_feedback).drop_duplicates()\n        feedback = feedback.with_column(\"chat_date\", F.col(\"chat_date\").cast(T.DateType()))\n        feedback = feedback.with_column(\"customer_id\", F.col(\"customer_id\").cast(T.StringType()))\n    \n        feedback.write.mode(\"overwrite\").save_as_table(\"temp_feedback\")\n    \n        feedback_df = session.table(\"temp_feedback\")\n        \n        comments_df = session.table(\"comments_temp\")\n        \n        temp_feedback_df = feedback_df.join(comments_df, feedback_df[\"internal_id\"] == comments_df[\"id\"]) \\\n                                        .select(feedback_df[\"feedback_id\"], \n                                                feedback_df[\"customer_id\"], \n                                                feedback_df[\"chat_date\"], \n                                                feedback_df[\"internal_id\"], \n                                                comments_df[\"comment\"])\n      \n        feedback_sentiment_df = temp_feedback_df.with_columns([\"sentiment\"], [sentiment(F.col(\"comment\"))])\n      \n        feedback_sentiment_df.write.mode(\"append\").save_as_table('feedback_sentiment')\n\n    print ('Adding feedback for churn customers')\n    add_sentiment(churn_customers, False)\n    print ('Adding feedback for happy customers')\n    add_sentiment(active_customers, True)\n    \n    return \"Transactions added\"\n\n#session.sproc.register(\n#    func=add_new_top_sales,\n#    name=\"add_new_top_sales_sproc\",\n#    replace=True,\n#    is_permanent=True,\n#    stage_location=\"@ML_STAGE\",\n#    packages=['snowflake-snowpark-python', 'snowflake-ml-python'],\n#    return_type=T.StringType()\n#)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72aadc0a-0108-4a4d-b5f5-f9139524d251",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d62d163f-e002-4b87-a16b-f9825d0f0bfb",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "31cca694-ad80-4fa2-9aca-9429f8bfcf68",
   "metadata": {
    "language": "python",
    "name": "generate_more_data"
   },
   "outputs": [],
   "source": "# Build features for the timestamp of the last sales. This will create the first customer \n# behavior profile in the training baseline baseline_features_builing_dataset\n# With theat profile, we call the function to add more sales based on that customer profile\n\ndb = session.get_current_database()\nsc = session.get_current_schema()\ntable_features = 'baseline_features_builing_dataset'\n\nsession.sql(f'use schema {sc}').collect()\nsession.sql(f'drop table if exists {table_features}').collect()\n\nsales_df = session.table(\"sales\")\nn_transactions = sales_df.count()\nprint (n_transactions)\n\nfeedback_sentiment_df = session.table(\"feedback_sentiment\")\nnum_reviews = feedback_sentiment_df.count()\nprint (f'num reviews: {num_reviews}')\n\nfor i in range(7):\n\n    # Customers profiles fora given timestmp (last sales date)\n    sales_df = session.table(\"sales\")\n\n    last_sale_timestamp = sales_df.select(F.max(F.col(\"transaction_date\"))).collect()[0][0]\n\n    print (f'Building features for timestamp: {last_sale_timestamp}')\n    uc01_feature_engineering_generation(db, sc, 'SALES', 'FEEDBACK_SENTIMENT', last_sale_timestamp, table_features)\n    \n    #add 30 more days of sales to thee sales table, based on the last\n    #profile of custoemr_churn_testing\n    print (f'adding more sales')\n    add_new_top_sales (session, table_features, 'sales',30)\n\n    n_transactions = sales_df.count()\n    print (n_transactions)\n    ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8d4123c-16ab-4669-b6ee-fc9e39def22a",
   "metadata": {
    "language": "sql",
    "name": "cell20"
   },
   "outputs": [],
   "source": "select timestamp,  count(*) from baseline_features_builing_dataset\ngroup by timestamp\norder by timestamp desc;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2fdc0486-e302-4149-a6a3-f26d3d00d4aa",
   "metadata": {
    "language": "sql",
    "name": "cell27"
   },
   "outputs": [],
   "source": "create table baseline  clone baseline_features_builing_dataset;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ffccd898-8e38-4efa-aeb3-9559257aa254",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": "db = session.get_current_database()\nsc = session.get_current_schema()\nprint (f'database: {db}, schema: {sc}')\n\nsession.call('UTILS.uc_01_label_churn_sproc', db, sc, 'baseline_features_builing_dataset', \n             'baseline_features_builing_dataset_labeled', 30 )\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0b2edf4-e530-4f8b-b1d4-6e7781e613aa",
   "metadata": {
    "language": "sql",
    "name": "cell29"
   },
   "outputs": [],
   "source": "SELECT \n    TIMESTAMP,\n    SUM(CASE WHEN churned = 0 THEN 1 ELSE 0 END) AS not_churned,\n    SUM(CASE WHEN churned = 1 THEN 1 ELSE 0 END) AS churned\nFROM baseline_features_builing_dataset_labeled\nGROUP BY TIMESTAMP\nORDER BY TIMESTAMP;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "914d697e-bf3f-4638-a94b-d17b5110b2bd",
   "metadata": {
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": "df = session.table('baseline_features_builing_dataset_labeled')\n\ntimestamp_to_drop = df.select(F.min(F.col(\"timestamp\"))).collect()[0][0]\n\nsql_cmd = f\"\"\"\n        delete from sales where transaction_date < '{timestamp_to_drop}'\n        \"\"\"\n\nsession.sql(sql_cmd).collect()\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1de93bbb-4392-4eec-8ecf-0af969a1d3b9",
   "metadata": {
    "language": "sql",
    "name": "cell42"
   },
   "outputs": [],
   "source": "SELECT \n    TIMESTAMP,\n    SUM(CASE WHEN churned = 0 THEN 1 ELSE 0 END) AS not_churned,\n    SUM(CASE WHEN churned = 1 THEN 1 ELSE 0 END) AS churned\nFROM baseline_features_builing_dataset_labeled\nGROUP BY TIMESTAMP\nORDER BY TIMESTAMP;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9fb88e0-53be-401d-a044-0b3768e7c635",
   "metadata": {
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": "describe table sales;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "48925cc5-09fe-4290-ad94-8b30025ab998",
   "metadata": {
    "language": "sql",
    "name": "cell28"
   },
   "outputs": [],
   "source": "describe table baseline_features_builing_dataset;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c2cfac3-073d-406c-a737-f7dac6bb879f",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport random\nfrom datetime import datetime, timedelta\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark import functions as F\n\nnum_customers = 5000\nnum_transactions = num_customers * 15\nnum_feedback_reports = num_customers * 2\n\n\npayment_methods = ['Credit Card', 'Paypal', 'Apple Pay']\nproduct_segments = ['Fashion', 'Electronics', 'Beauty', 'Groceries', 'Home', 'Toys', 'Books']\n# Drift, less locations\nlocations = ['Madrid', 'Barcelona', 'Paris']\n# Drift, less segments\ncustomer_segments = ['Standard', 'Gold']\n\n\ndef generate_data_skew (first_transaction_date, period):\n\n    customers = []\n    for i in range(num_customers):\n        customer_id = f\"CUST2-{i}\"\n        age = random.randint(18, 99)\n        gender = 'Male' if random.choice([True, False]) else 'Female'\n        location = random.choice(locations)\n        signup_date = first_transaction_date - timedelta(days=random.randint(365,900))\n        customer_segment = random.choice(customer_segments)\n        \n        customers.append ([customer_id, age, gender, location, signup_date, customer_segment])\n\n    df_customers = pd.DataFrame(customers, columns= [\n        \"CUSTOMER_ID\", \"AGE\", \"GENDER\", \"LOCATION\", \"SIGNUP_DATE\", \"CUSTOMER_SEGMENT\"\n    ])\n\n    customers = session.create_dataframe(df_customers).drop_duplicates()\n    customers = customers.with_column(\"signup_date\", F.col(\"signup_date\").cast(T.DateType()))\n    customers.write.mode(\"overwrite\").save_as_table(\"NEW_CUSTOMERS\")\n\n    transactions = []\n    for i in range(num_transactions):\n        transaction_id = f\"TRANS2-{i+1}\"\n        customer_id = f\"CUST2-{random.randint(1, num_customers)}\"\n        transaction_date = first_transaction_date + timedelta(days=random.randint(0,period))\n        total_amount = round(random.uniform(10, 500), 2)  ######## DRIFT - CUSTOMERS SPENING MUCH LESS MONEY\n        num_items = random.randint(1, 10)\n        discount_applied = bool(random.randint(0, 1))\n        payment_method = random.choice(payment_methods)\n        \n        transactions.append([transaction_id, customer_id, transaction_date, total_amount, num_items, discount_applied, payment_method])\n\n    # Creating the DataFrame for transactions\n    df_transactions = pd.DataFrame(transactions, columns=[\n        \"TRANSACTION_ID\", \"CUSTOMER_ID\", \"TRANSACTION_DATE\", \"TOTAL_AMOUNT\", \n        \"NUM_ITEMS\", \"DISCOUNT_APPLIED\", \"PAYMENT_METHOD\"\n    ])\n\n    transactions = session.create_dataframe(df_transactions).drop_duplicates()\n    transactions = transactions.with_column(\"transaction_date\", F.col(\"transaction_date\").cast(T.DateType()))\n    transactions.write.mode(\"overwrite\").save_as_table(\"NEW_SALES\")\n    \n   # Feedback data generation\n\n    comments_df = session.table(\"comments_temp\")\n    \n    feedback_df = session.sql(f\"\"\"\n        SELECT \n        'FB-' || TO_CHAR(SEQ8()) AS feedback_id,\n        'CUST-' || TO_CHAR(UNIFORM(1, 5000, RANDOM())) AS customer_id,\n        DATEADD(DAY, -UNIFORM(0, 365, RANDOM()), CURRENT_DATE) AS chat_date,\n        UNIFORM(1, 9, RANDOM()) AS internal_id\n    FROM TABLE(GENERATOR(ROWCOUNT => {num_feedback_reports}))\n    \"\"\")\n    \n    final_feedback_df = feedback_df.join(comments_df, feedback_df[\"internal_id\"] == comments_df[\"id\"]) \\\n                                    .select(feedback_df[\"feedback_id\"], \n                                            feedback_df[\"customer_id\"], \n                                            feedback_df[\"chat_date\"], \n                                            feedback_df[\"internal_id\"], \n                                            comments_df[\"comment\"])\n    \n    final_feedback_df.write.mode(\"overwrite\").save_as_table(\"NEW_FEEDBACK_RAW2\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de04b39c-919d-48ab-a1ea-d4567fbd832e",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "num_days_per_batch = 31\n\nsales_df = session.table(\"SALES\")\n\nlast_sale_timestamp = sales_df.select(F.max(F.col(\"transaction_date\"))).collect()[0][0]\n\nprint (f'Starting at {last_sale_timestamp} ')\n# Add some skew data for 1 batches\ngenerate_data_skew(last_sale_timestamp, num_days_per_batch * 1)  ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a64631de-43d9-4d29-add4-ba1b21cadb7b",
   "metadata": {
    "language": "sql",
    "name": "cell39"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c6c97d4-6655-42ea-820d-06d810c47e62",
   "metadata": {
    "language": "python",
    "name": "cell37"
   },
   "outputs": [],
   "source": "from snowflake.cortex import sentiment\nimport snowflake.snowpark.functions as F\n\n\nfeedback_raw_df = session.table(\"new_feedback_raw2\")\n\nfeedback_sentiment_df = feedback_raw_df.with_columns([\"sentiment\"], [sentiment(F.col(\"comment\"))])\n\nfeedback_sentiment_df.write.mode(\"overwrite\").save_as_table(\"new_feedback_sentiment\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88f30591-9c96-498f-8863-df34b32be0d9",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport random\nfrom datetime import datetime, timedelta\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark import functions as F\nfrom snowflake import snowpark\n\ndef add_new_top_sales_skew (session: snowpark.Session, churn_base_table: str, \n                       new_sales_table:str , days_window: int):\n\n    def add_transactions (df, last_sales_timestamp, days_window):\n    \n        transactions = []\n        \n        for customer in df:\n\n            for i in range(random.randint(1,5)): #between 1 and 10 transactions in the period\n                customer_id = customer[\"CUSTOMER_ID\"]\n                    \n                payment_methods = ['Credit Card', 'Paypal', 'Apple Pay']\n            \n                transaction_id = f\"TRANS-N\"\n                customer_id = customer_id\n                \n                #if round(random.randint(1,10)) >= 6: # 60% buy in the entire period\n                days=random.randint(5,days_window)\n                #else: # the rest buy in the first quarter\n                #    days=random.randint(1,round(days_window/4)+1)\n\n                transaction_date = last_sales_timestamp + timedelta(days=random.randint(1,days))\n                \n                total_amount = round(random.uniform(50, 5000), 2)\n                num_items = random.randint(1, 5)\n                discount_applied = bool(random.randint(0, 1))\n                payment_method = random.choice(payment_methods)\n                    \n                transactions.append([transaction_id, customer_id, transaction_date, total_amount, num_items, discount_applied, payment_method])\n        \n        # Creating the DataFrame for transactions\n        df_transactions = pd.DataFrame(transactions, columns=[\n            \"TRANSACTION_ID\", \"CUSTOMER_ID\", \"TRANSACTION_DATE\", \"TOTAL_AMOUNT\", \n            \"NUM_ITEMS\", \"DISCOUNT_APPLIED\", \"PAYMENT_METHOD\"\n        ])\n        \n        df_transactions[\"TRANSACTION_DATE\"] = pd.to_datetime(df_transactions[\"TRANSACTION_DATE\"], errors=\"coerce\")\n    \n        transactions = session.create_dataframe(df_transactions).drop_duplicates()\n        transactions = transactions.with_column(\"TRANSACTION_DATE\", F.to_date(F.col(\"TRANSACTION_DATE\")))\n\n       # transactions = transactions.with_column(\"transaction_date\", F.col(\"transaction_date\").cast(T.DateType()))\n        transactions.write.mode(\"append\").save_as_table(new_sales_table)\n     \n        num_tran = transactions.count()\n        print (f'added {num_tran} transactions')\n\n    \n    churn_df = session.table(churn_base_table)\n        \n    latest_timestamp = churn_df.select(F.max(F.col(\"TIMESTAMP\"))).collect()[0][0]\n    \n    churn_df = churn_df.filter(F.col(\"TIMESTAMP\") == F.lit(latest_timestamp))\n\n    num_customers = churn_df.select(\"CUSTOMER_ID\").distinct().count()\n\n    all_customers_ordered_sentiment = churn_df.select(\"CUSTOMER_ID\").orderBy(F.col(\"SENTIMENT_AVG_2\").desc()).collect()\n\n    churn_rate = random.uniform(0.45, 0.55)\n    num_churn = int(num_customers * churn_rate)\n\n    churn_customers = all_customers_ordered_sentiment[:num_churn]\n    active_customers = all_customers_ordered_sentiment[num_churn:]\n    \n    last_sales_timestamp = session.table(new_sales_table).select(F.max(F.col(\"transaction_date\"))).collect()[0][0]\n    \n\n    print (\"Add for active customers\")\n    add_transactions(active_customers, last_sales_timestamp, days_window)\n\n\n    def add_sentiment(df, happy):\n        #add sentiment but no transactions for chun customers\n        feedback = []\n    \n        for customer in df:\n            feedback_id = 'FEEDBACK-N'\n            customer_id = customer[\"CUSTOMER_ID\"]\n            customer_id = customer_id\n            chat_date = last_sales_timestamp + timedelta(days=random.randint(1,days_window))\n            if happy:\n                internal_id = random.randint(6, 9) #from angry to neutral\n            else:\n                internal_id = random.randint(1, 4) #from angry to neutral\n            \n            feedback.append([feedback_id, customer_id, chat_date, internal_id])\n    \n        df_feedback = pd.DataFrame(feedback, columns=[\n                \"FEEDBACK_ID\", \"CUSTOMER_ID\", \"CHAT_DATE\",\n                \"INTERNAL_ID\"\n        ])\n    \n        feedback = session.create_dataframe(df_feedback).drop_duplicates()\n        feedback = feedback.with_column(\"chat_date\", F.col(\"chat_date\").cast(T.DateType()))\n        feedback = feedback.with_column(\"customer_id\", F.col(\"customer_id\").cast(T.StringType()))\n    \n        feedback.write.mode(\"overwrite\").save_as_table(\"temp_feedback\")\n    \n        feedback_df = session.table(\"temp_feedback\")\n        \n        comments_df = session.table(\"comments_temp\")\n        \n        temp_feedback_df = feedback_df.join(comments_df, feedback_df[\"internal_id\"] == comments_df[\"id\"]) \\\n                                        .select(feedback_df[\"feedback_id\"], \n                                                feedback_df[\"customer_id\"], \n                                                feedback_df[\"chat_date\"], \n                                                feedback_df[\"internal_id\"], \n                                                comments_df[\"comment\"])\n      \n        feedback_sentiment_df = temp_feedback_df.with_columns([\"sentiment\"], [sentiment(F.col(\"comment\"))])\n      \n        feedback_sentiment_df.write.mode(\"append\").save_as_table('new_feedback_sentiment')\n\n    print ('Adding feedback for churn customers')\n    add_sentiment(churn_customers, False)\n    print ('Adding feedback for happy customers')\n    add_sentiment(active_customers, True)\n    \n    return \"Transactions added\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbb94952-6f12-4255-87e8-f67c8166cb0f",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "# Build features for the timestamp of the last sales. This will create the first customer \n# behavior profile in the training baseline baseline_features_builing_dataset\n# With theat profile, we call the function to add more sales based on that customer profile\n\ndb = session.get_current_database()\nsc = session.get_current_schema()\ntable_features = 'baseline_features_builing_dataset'\n\nsession.sql(f'use schema {sc}').collect()\n\nsales_df = session.table(\"NEW_SALES\")\nn_transactions = sales_df.count()\nprint (n_transactions)\n\nprint (f'num reviews: {num_reviews}')\n\nfor i in range(4):\n\n    # Customers profiles fora given timestmp (last sales date)\n    sales_df = session.table(\"NEW_SALES\")\n\n    last_sale_timestamp = sales_df.select(F.max(F.col(\"transaction_date\"))).collect()[0][0]\n\n    print (f'Building features for timestamp: {last_sale_timestamp}')\n    uc01_feature_engineering_generation(db, sc, 'NEW_SALES', 'NEW_FEEDBACK_SENTIMENT', last_sale_timestamp, table_features)\n    \n    #add 30 more days of sales to thee sales table, based on the last\n    #profile of custoemr_churn_testing\n    print (f'adding more sales')\n    add_new_top_sales_skew (session, table_features, 'NEW_SALES',30)\n\n    n_transactions = sales_df.count()\n    print (n_transactions)\n    ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "347f5155-803b-4388-bfe3-b321018f98bf",
   "metadata": {
    "language": "sql",
    "name": "cell38"
   },
   "outputs": [],
   "source": "select min(transaction_date), max(transaction_date) from NEW_SALES;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "acb1e07c-b33d-44c7-a04e-9471d71fb8f1",
   "metadata": {
    "language": "sql",
    "name": "cell40"
   },
   "outputs": [],
   "source": "select min(transaction_date), max(transaction_date) from SALES;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8dec495e-72fc-411a-af36-6262ed9114e7",
   "metadata": {
    "name": "cell24",
    "collapsed": false
   },
   "source": "We have simulated sales based on some customer profile. We are going to write customer, sales and sentiment on CSV tables that will be used later to simulate a pipeline ingesting data and training ML models producing inference to detect possible customer churn."
  },
  {
   "cell_type": "code",
   "id": "081c0a00-3867-45a0-a3bc-f940a56205fa",
   "metadata": {
    "language": "sql",
    "name": "create_csv_stage"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STAGE CSV\n  DIRECTORY = (ENABLE = TRUE)\n  ENCRYPTION = ( TYPE = 'SNOWFLAKE_SSE' );",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d79e051-166b-4589-b49a-f7aad6cd0a41",
   "metadata": {
    "language": "python",
    "name": "def_unload_table_by_month"
   },
   "outputs": [],
   "source": "import snowflake.snowpark as snowpark\nimport  snowflake.snowpark.functions as F\nimport datetime\n\n\ndef unload_table_by_month(session: snowpark.Session, stage_name: str, table: str,\n                                columns: str, date_column: str):\n    # Read sales data\n    df = session.table(table)\n\n    # Ensure transaction_date is in DATE format\n    #df = df.with_column(\"transaction_date\", to_date(col(\"transaction_date\")))\n\n    # Extract year and week for partitioning\n    df = df.with_column(\"year\", F.year(F.col(date_column)))\n    df = df.with_column(\"month\", F.month(F.col(date_column)))\n\n    # Get distinct year-week pairs\n    months = df.select(\"year\", \"month\").distinct().collect()\n\n    # Iterate over each week and export CSV\n    for row in months:\n        y, m = row[\"YEAR\"], row[\"MONTH\"]\n        output_file = f\"{table}_{y}_{m}.csv\"\n        query = f\"\"\"\n            COPY INTO @{stage_name}/{output_file}\n            FROM (SELECT {columns}           \n            FROM {table} WHERE year({date_column}) = {y} AND month({date_column}) = {m})\n            FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY='\"')\n            SINGLE = TRUE;\n        \"\"\"\n        session.sql(query).collect()\n        print(f\"Exported {output_file} to {stage_name}\")\n\n    return f\"CSV export completed to {stage_name}\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4285327-295f-4cf3-8a1d-931619e0c669",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "sales_columns = \"\"\"TRANSACTION_ID,\n                    CUSTOMER_ID,\n                    TRANSACTION_DATE,\n                    DISCOUNT_APPLIED,\n                    NUM_ITEMS,\n                    PAYMENT_METHOD, \n                    TOTAL_AMOUNT\"\"\" \n\nunload_table_by_month (session, 'CSV', 'sales', sales_columns, 'transaction_date')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97c05772-e94a-4610-8d36-7f58d1132b1d",
   "metadata": {
    "language": "python",
    "name": "unload_feedback"
   },
   "outputs": [],
   "source": "feedback_columns = \"\"\"CHAT_DATE,\n                    COMMENT,\n                    CUSTOMER_ID,\n                    FEEDBACK_ID,\n                    INTERNAL_ID\n                    \"\"\" \n\nunload_table_by_month (session, 'CSV', 'feedback_raw', \n                       feedback_columns, 'chat_date')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "632bc587-47b9-439e-b4c6-294443a5f8bd",
   "metadata": {
    "language": "python",
    "name": "unload_sentiment"
   },
   "outputs": [],
   "source": "feedback_sentiment_columns = \"\"\"\n                    FEEDBACK_ID,\n                    CHAT_DATE,\n                    CUSTOMER_ID,\n                    INTERNAL_ID,\n                    COMMENT,\n                    SENTIMENT\n                    \"\"\" \n\nunload_table_by_month (session, 'CSV', 'feedback_sentiment', \n                       feedback_sentiment_columns, 'chat_date')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7479ad7b-4a90-4cd5-b392-6b42d3db6331",
   "metadata": {
    "language": "sql",
    "name": "unload_customers"
   },
   "outputs": [],
   "source": "COPY INTO @CSV/customers.csv\n            FROM (SELECT\n                CUSTOMER_ID, AGE, CUSTOMER_SEGMENT, GENDER, LOCATION, SIGNUP_DATE\n            FROM customers)\n            FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY='\"')\n            SINGLE = TRUE;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df873cda-c8f2-46a5-a4ce-fa0a1397b2ab",
   "metadata": {
    "language": "sql",
    "name": "cell35"
   },
   "outputs": [],
   "source": "COPY INTO @CSV/new_customers.csv\n            FROM (SELECT\n                CUSTOMER_ID, AGE, CUSTOMER_SEGMENT, GENDER, LOCATION, SIGNUP_DATE\n            FROM new_customers)\n            FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY='\"')\n            SINGLE = TRUE;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c5cd512-90fc-4181-a1d7-a66f1049a9d9",
   "metadata": {
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": "sales_columns = \"\"\"TRANSACTION_ID,\n                    CUSTOMER_ID,\n                    TRANSACTION_DATE,\n                    DISCOUNT_APPLIED,\n                    NUM_ITEMS,\n                    PAYMENT_METHOD, \n                    TOTAL_AMOUNT\"\"\" \n\nunload_table_by_month (session, 'CSV', 'new_sales', sales_columns, 'transaction_date')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9120d16c-608d-4240-8170-5d3354976a95",
   "metadata": {
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": "feedback_columns = \"\"\"CHAT_DATE,\n                    COMMENT,\n                    CUSTOMER_ID,\n                    FEEDBACK_ID,\n                    INTERNAL_ID\n                    \"\"\" \n\nunload_table_by_month (session, 'CSV', 'new_feedback_raw2', \n                       feedback_columns, 'chat_date')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa4d2883-10fa-45d2-a5cf-1659e58b414c",
   "metadata": {
    "language": "sql",
    "name": "cell25"
   },
   "outputs": [],
   "source": "ls @CSV;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a549ecc2-420d-4983-9b88-009d4d566153",
   "metadata": {
    "language": "sql",
    "name": "cell41"
   },
   "outputs": [],
   "source": "remove @csv/new_sales_2024_12.csv",
   "execution_count": null
  }
 ]
}